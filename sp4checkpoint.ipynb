{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, GRU, Dense, Dropout, BatchNormalization, LayerNormalization, Reshape, Permute, Bidirectional, Add, Attention, Flatten, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, Callback\n",
    "from tensorflow.keras.layers import Layer, Concatenate\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import f1_score\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import noisereduce as nr\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, sosfilt\n",
    "\n",
    "# Add this to create a directory for saving figures\n",
    "FIGURES_DIR = 'training_figures'\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force GPU usage\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.set_visible_devices(physical_devices[0], 'GPU')\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "else:\n",
    "    print(\"No GPU devices found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and preprocessing\n",
    "def load_and_preprocess_audio(file_path, sr=16000, duration=4):\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=sr, duration=duration)\n",
    "\n",
    "        # Data Augmentation (increased probability and variety)\n",
    "        if np.random.random() < 0.5:  # 50% chance of applying augmentation\n",
    "            augmentation_type = np.random.choice(['noise', 'pitch', 'speed'])\n",
    "            if augmentation_type == 'noise':\n",
    "                noise = np.random.randn(len(audio)) * 0.005\n",
    "                audio = audio + noise\n",
    "            elif augmentation_type == 'pitch':\n",
    "                audio = librosa.effects.pitch_shift(audio, sr=sr, n_steps=np.random.uniform(-2, 2))\n",
    "            else:  # speed\n",
    "                audio = librosa.effects.time_stretch(audio, rate=np.random.uniform(0.8, 1.2))\n",
    "\n",
    "        # Normalize audio\n",
    "        audio = audio - np.mean(audio)\n",
    "        audio = audio / np.max(np.abs(audio))\n",
    "\n",
    "        # Pad if necessary\n",
    "        if len(audio) < sr * duration:\n",
    "            audio = np.pad(audio, (0, sr * duration - len(audio)))\n",
    "        return audio\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio, sr=16000, n_mels=80, n_fft=2048, hop_length=512):\n",
    "    if audio is None:\n",
    "        return None\n",
    "\n",
    "    # Extract mel spectrogram\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=audio,\n",
    "        sr=sr,\n",
    "        n_mels=n_mels,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length\n",
    "    )\n",
    "    log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "    # Normalize features\n",
    "    log_mel_spec = (log_mel_spec - np.mean(log_mel_spec)) / np.std(log_mel_spec)\n",
    "    return log_mel_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze class distribution for debugging class imbalance\n",
    "def analyze_class_distribution(data_path):\n",
    "    real_count = len([f for f in os.listdir(os.path.join(data_path, 'real')) if f.endswith('.wav')])\n",
    "    fake_count = len([f for f in os.listdir(os.path.join(data_path, 'fake')) if f.endswith('.wav')])\n",
    "    total = real_count + fake_count\n",
    "    print(f\"\\nClass Distribution for {data_path}:\")\n",
    "    print(f\"Real: {real_count} ({real_count/total*100:.2f}%)\")\n",
    "    print(f\"Fake: {fake_count} ({fake_count/total*100:.2f}%)\")\n",
    "    return {'real': real_count, 'fake': fake_count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator with sample weights and debugging utilities\n",
    "def data_generator(data_path, batch_size=128, shuffle=True):\n",
    "    real_files = [os.path.join(data_path, 'real', f) for f in os.listdir(os.path.join(data_path, 'real')) if f.endswith('.wav')]\n",
    "    fake_files = [os.path.join(data_path, 'fake', f) for f in os.listdir(os.path.join(data_path, 'fake')) if f.endswith('.wav')]\n",
    "    \n",
    "    all_files = real_files + fake_files\n",
    "    labels = [1] * len(real_files) + [0] * len(fake_files)\n",
    "    \n",
    "    total_samples = len(all_files)\n",
    "    class_weights = {\n",
    "        1: total_samples / (2 * len(real_files)),\n",
    "        0: total_samples / (2 * len(fake_files))\n",
    "    }\n",
    "    \n",
    "    while True:\n",
    "        if shuffle:\n",
    "            temp = list(zip(all_files, labels))\n",
    "            np.random.shuffle(temp)\n",
    "            all_files, labels = zip(*temp)\n",
    "        \n",
    "        for i in range(0, len(all_files), batch_size):\n",
    "            batch_files = all_files[i:i+batch_size]\n",
    "            batch_labels = labels[i:i+batch_size]\n",
    "            \n",
    "            batch_x = []\n",
    "            batch_y = []\n",
    "            batch_weights = []\n",
    "            max_length = 0\n",
    "            \n",
    "            for file_path, label in zip(batch_files, batch_labels):\n",
    "                audio = load_and_preprocess_audio(file_path)\n",
    "                features = extract_features(audio)\n",
    "                \n",
    "                if features is not None:\n",
    "                    batch_x.append(features.T)\n",
    "                    batch_y.append(label)\n",
    "                    weight = class_weights[label]\n",
    "                    batch_weights.append(weight)\n",
    "                    max_length = max(max_length, features.T.shape[0])\n",
    "            \n",
    "            # Pad sequences to max_length\n",
    "            padded_batch_x = []\n",
    "            for x in batch_x:\n",
    "                padded_x = np.pad(x, ((0, max_length - x.shape[0]), (0, 0)), mode='constant')\n",
    "                padded_batch_x.append(padded_x)\n",
    "            \n",
    "            if padded_batch_x:\n",
    "                yield np.array(padded_batch_x), np.array(batch_y), np.array(batch_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFM(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MFM, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        shape = tf.shape(inputs)\n",
    "        return tf.reshape(tf.math.maximum(inputs[:,:,:shape[-1]//2], inputs[:,:,shape[-1]//2:]), (shape[0], shape[1], shape[-1]//2))\n",
    "    \n",
    "def create_enhanced_lc_grnn_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = BatchNormalization()(inputs)\n",
    "\n",
    "    # Light Convolutional layers with increased regularization\n",
    "    x = Conv1D(32, 5, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.02))(x)\n",
    "    x = MFM()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    x = Conv1D(64, 3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.02))(x)\n",
    "    x = MFM()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    # Bidirectional GRU layers with residual connections and increased regularization\n",
    "    for units in [64, 32]:\n",
    "        gru = Bidirectional(GRU(units // 2, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.02)))\n",
    "        gru_output = gru(x)\n",
    "        gru_output = Dense(K.int_shape(x)[-1])(gru_output)\n",
    "        x = Add()([x, gru_output])\n",
    "        x = LayerNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "\n",
    "    # Attention mechanism\n",
    "    attention = Attention()([x, x])\n",
    "    x = Add()([x, attention])\n",
    "\n",
    "    # Final GRU layer\n",
    "    x = Bidirectional(GRU(16, kernel_regularizer=tf.keras.regularizers.l2(0.02)))(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # Dense layers with increased regularization\n",
    "    x = Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.02))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to data\n",
    "train_data_path = 'datasetNEW/train'\n",
    "dev_data_path = 'datasetNEW/dev'\n",
    "eval_data_path = 'datasetNEW/eval'\n",
    "\n",
    "# Analyze class distribution\n",
    "print(\"Training set class distribution:\")\n",
    "analyze_class_distribution(train_data_path)\n",
    "analyze_class_distribution(dev_data_path)\n",
    "analyze_class_distribution(eval_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files(path):\n",
    "    real_files = [f for f in os.listdir(os.path.join(path, 'real')) if f.endswith('.wav')]\n",
    "    fake_files = [f for f in os.listdir(os.path.join(path, 'fake')) if f.endswith('.wav')]\n",
    "    return len(real_files) + len(fake_files)\n",
    "\n",
    "# Create generators\n",
    "batch_size = 128  # Increased batch size\n",
    "train_gen = data_generator(train_data_path, batch_size=batch_size)\n",
    "dev_gen = data_generator(dev_data_path, batch_size=batch_size)\n",
    "eval_gen = data_generator(eval_data_path, batch_size=batch_size)\n",
    "\n",
    "# Calculate steps per epoch\n",
    "train_samples_count = count_files(train_data_path)\n",
    "dev_samples_count = count_files(dev_data_path)\n",
    "eval_samples_count = count_files(eval_data_path)\n",
    "\n",
    "steps_per_epoch = train_samples_count // batch_size\n",
    "validation_steps = dev_samples_count // batch_size\n",
    "eval_steps = eval_samples_count // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom callback to save training history plots after each epoch\n",
    "class PlotTrainingHistory(Callback):\n",
    "    def __init__(self, model_name='model'):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Plot training history\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.model.history.history['accuracy'], label='Training Accuracy')\n",
    "        plt.plot(self.model.history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.model.history.history['loss'], label='Training Loss')\n",
    "        plt.plot(self.model.history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        # Save the plot to a file\n",
    "        filepath = os.path.join(FIGURES_DIR, f'{self.model_name}_epoch_{epoch+1}.png')\n",
    "        plt.savefig(filepath)\n",
    "        plt.close()\n",
    "        print(f'Training history plot saved to {filepath}')\n",
    "\n",
    "# Callbacks\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Create a checkpoint directory to save the model weights after each epoch\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=False,  # Save every epoch, not just the best\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "plot_training_callback = PlotTrainingHistory(model_name='audio_model') # create instance here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile the model\n",
    "input_shape = (None, 80)\n",
    "model = create_enhanced_lc_grnn_model(input_shape)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=50,  # Reduced number of epochs\n",
    "    validation_data=dev_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[reduce_lr, early_stopping, checkpoint_callback, plot_training_callback], # add the callback here\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nEvaluating on Evaluation Dataset:\")\n",
    "eval_results = model.evaluate(eval_gen, steps=eval_steps)\n",
    "print(f\"Evaluation Results - Loss: {eval_results[0]}, Accuracy: {eval_results[1]}, AUC: {eval_results[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, roc_curve\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# EER and t-DCF related imports\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Define t-DCF parameters (these should be set according to your task)\n",
    "p_target = 0.05  # Prior probability of target speaker\n",
    "c_miss = 1       # Cost of a miss (false negative)\n",
    "c_false_alarm = 1 # Cost of a false alarm (false positive)\n",
    "\n",
    "# Reset the generator to its initial state\n",
    "eval_gen = data_generator(eval_data_path, batch_size=batch_size)\n",
    "\n",
    "# Generate predictions and collect true labels\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for _ in range(eval_steps):\n",
    "    batch_x, batch_y, _ = next(eval_gen)\n",
    "    batch_pred = model.predict(batch_x, verbose=0)\n",
    "    y_pred.extend(batch_pred.flatten())\n",
    "    y_true.extend(batch_y)\n",
    "\n",
    "# Convert to numpy arrays and ensure same length\n",
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_true)\n",
    "min_len = min(len(y_pred), len(y_true))\n",
    "y_pred = y_pred[:min_len]\n",
    "y_true = y_true[:min_len]\n",
    "\n",
    "# Convert predictions to binary (0 or 1)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(y_true, y_pred_binary)\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_binary)\n",
    "\n",
    "# Convert confusion matrix to percentages\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "# Visualize confusion matrix as percentages\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_percentage, annot=True, fmt='.2f', cmap='Blues', cbar_kws={'format': '%.0f%%'})\n",
    "plt.title('Confusion Matrix (Percentage)')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig(os.path.join(FIGURES_DIR, 'confusion_matrix.png'))  # Save confusion matrix\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "# EER Calculation\n",
    "#---------------------------------------------------------------\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred, pos_label=1)\n",
    "# Find the EER threshold\n",
    "eer_threshold = thresholds[np.argmin(np.abs(fpr - (1-tpr)))]\n",
    "\n",
    "# Calculate EER\n",
    "eer = fpr[np.argmin(np.abs(fpr - (1-tpr)))]\n",
    "\n",
    "print(f\"EER: {eer:.4f}\")\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "# t-DCF Calculation\n",
    "#---------------------------------------------------------------\n",
    "def calculate_t_dcf(y_true, y_pred, p_target, c_miss, c_false_alarm, threshold):\n",
    "    \"\"\"\n",
    "    Calculates the tuned Detection Cost Function (t-DCF).\n",
    "    \"\"\"\n",
    "    # Apply threshold to get binary predictions\n",
    "    y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "\n",
    "    # Calculate confusion matrix elements\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred_binary).ravel()\n",
    "\n",
    "    # Calculate False Alarm Rate (FAR) and Miss Rate (FR)\n",
    "    far = fp / (tn + fp)\n",
    "    fr = fn / (tp + fn)\n",
    "\n",
    "    # Calculate t-DCF\n",
    "    t_dcf = c_miss * p_target * fr + c_false_alarm * (1 - p_target) * far\n",
    "\n",
    "    return t_dcf\n",
    "\n",
    "# Calculate t-DCF using the EER threshold\n",
    "t_dcf = calculate_t_dcf(y_true, y_pred, p_target, c_miss, c_false_alarm, eer_threshold)\n",
    "print(f\"t-DCF: {t_dcf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import noisereduce as nr\n",
    "from scipy.signal import butter, sosfilt\n",
    "import soundfile as sf\n",
    "\n",
    "def denoise_and_amplify(audio, sr):\n",
    "    try:\n",
    "        # Noise Reduction\n",
    "        reduced_noise = nr.reduce_noise(y=audio, sr=sr, stationary=False)\n",
    "        return reduced_noise\n",
    "    except Exception as e:\n",
    "        print(f\"Error in denoise_and_amplify: {e}\")\n",
    "        return audio  # Return original audio if an error occurs\n",
    "\n",
    "def preprocess_and_visualize(file_path, sr=16000, duration=4):\n",
    "    # Load the audio file\n",
    "    audio, sr = librosa.load(file_path, sr=sr, duration=duration)\n",
    "    \n",
    "    # Save original audio\n",
    "    sf.write('original_audio.wav', audio, sr)\n",
    "    \n",
    "    # Original Mel Spectrogram\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=80, n_fft=2048, hop_length=512)\n",
    "    librosa.display.specshow(librosa.power_to_db(mel_spec, ref=np.max), sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.title('Original Mel Spectrogram')\n",
    "    \n",
    "    # Noise Reduction using denoise_and_amplify function\n",
    "    reduced_noise = denoise_and_amplify(audio, sr)\n",
    "    sf.write('noise_reduced_audio.wav', reduced_noise, sr)\n",
    "    \n",
    "    # Final Mel Spectrogram\n",
    "    plt.subplot(1, 3, 3)\n",
    "    final_mel_spec = librosa.feature.melspectrogram(y=reduced_noise, sr=sr, n_mels=80, n_fft=2048, hop_length=512)\n",
    "    librosa.display.specshow(librosa.power_to_db(final_mel_spec, ref=np.max), sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.title('Final Mel Spectrogram')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, 'mel_spectrograms.png')) # saves graphs\n",
    "    plt.close()\n",
    "\n",
    "# Use the function\n",
    "file_path = 'A_2582_0_A.wav'\n",
    "preprocess_and_visualize(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
