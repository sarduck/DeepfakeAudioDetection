<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Deepfake Detector</title>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
    <style>
        .upload-area {
            border: 2px dashed #cbd5e0;
            transition: all 0.3s ease;
            padding: 2rem;
            text-align: center;
            cursor: pointer;
        }
        .upload-area:hover {
            border-color: #4299e1;
            background-color: #f7fafc;
        }
        .result-card {
            transition: all 0.3s ease;
        }
        .result-card:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        .visualization-section {
            transition: all 0.3s ease;
        }
        .visualization-card {
            transition: all 0.3s ease;
        }
        .visualization-card:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        .model-select-container {
            margin: 15px 0;
            text-align: center;
        }
        .model-select-container label {
            margin-right: 10px;
            font-weight: bold;
        }
        .model-select-container select {
            padding: 8px;
            border-radius: 4px;
            border: 1px solid #ccc;
            background-color: white;
            font-size: 14px;
        }
        #modelUsedText {
            font-size: 14px;
            color: #666;
            margin-top: 5px;
        }
        .loading-spinner {
            display: none;
            text-align: center;
            padding: 2rem;
        }
        .file-input {
            display: none;
        }
        .file-label {
            display: inline-block;
            padding: 8px 16px;
            background-color: #4299e1;
            color: white;
            border-radius: 4px;
            cursor: pointer;
            transition: background-color 0.3s;
        }
        .file-label:hover {
            background-color: #3182ce;
        }
        .upload-button {
            display: block;
            width: 100%;
            max-width: 200px;
            margin: 20px auto;
            padding: 10px 20px;
            background-color: #4299e1;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            transition: background-color 0.3s;
        }
        .upload-button:hover {
            background-color: #3182ce;
        }
        .upload-button:disabled {
            background-color: #cbd5e0;
            cursor: not-allowed;
        }
        .record-button {
            width: 64px;
            height: 64px;
            border-radius: 50%;
            background-color: #e53e3e;
            color: white;
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        .record-button:hover {
            background-color: #c53030;
            transform: scale(1.05);
        }
        .record-button.recording {
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0% {
                transform: scale(1);
                box-shadow: 0 0 0 0 rgba(229, 62, 62, 0.7);
            }
            70% {
                transform: scale(1.05);
                box-shadow: 0 0 0 10px rgba(229, 62, 62, 0);
            }
            100% {
                transform: scale(1);
                box-shadow: 0 0 0 0 rgba(229, 62, 62, 0);
            }
        }
    </style>
</head>
<body class="bg-gray-100 min-h-screen">
    <div class="container mx-auto px-4 py-8">
        <div class="max-w-4xl mx-auto">
            <h1 class="text-4xl font-bold text-center text-gray-800 mb-8">Audio Deepfake Detector</h1>
            
            <!-- Models Description Section -->
            <div class="bg-white rounded-lg shadow-lg p-6 mb-8">
                <h2 class="text-2xl font-semibold text-center mb-6">About Our Detection Models</h2>
                
                <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                    <!-- WGAN Model Description -->
                    <div class="bg-blue-50 rounded-lg p-4">
                        <h3 class="text-xl font-semibold text-blue-700 mb-3">WGAN Model</h3>
                        <p class="text-gray-700 mb-3">
                            The WGAN (Wasserstein Generative Adversarial Network) model offers superior performance in audio deepfake detection by utilizing advanced adversarial training techniques.
                        </p>
                        <ul class="list-disc pl-5 text-gray-700">
                            <li>Highly adaptive to different types of audio manipulations</li>
                            <li>Robust against sophisticated deepfake algorithms</li>
                            <li>Self-attention mechanism for improved feature extraction</li>
                            <li>Higher accuracy on a diverse range of audio samples</li>
                        </ul>
                    </div>
                    
                    <!-- Bi-GRU-RNN Model Description -->
                    <div class="bg-green-50 rounded-lg p-4">
                        <h3 class="text-xl font-semibold text-green-700 mb-3">Bi-GRU-RNN Model</h3>
                        <p class="text-gray-700 mb-3">
                            The Bi-GRU-RNN (Bidirectional Gated Recurrent Unit Recurrent Neural Network) offers state-of-the-art architecture with computational efficiency.
                        </p>
                        <ul class="list-disc pl-5 text-gray-700">
                            <li>Uses 25% less computational power than alternatives</li>
                            <li>Bidirectional analysis captures temporal patterns in both directions</li>
                            <li>Effective feature extraction through convolution and recurrent layers</li>
                            <li>Faster inference time with maintained accuracy</li>
                        </ul>
                    </div>
                </div>
            </div>
            
            <!-- Audio Input Methods Section (containing both upload and record) -->
            <div class="mb-8">
                <h2 class="text-2xl font-semibold text-center mb-6">Audio Input Methods</h2>
                
                <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                    <!-- Upload Audio File Section -->
                    <div class="bg-white rounded-lg shadow-lg p-6">
                        <div class="upload-container">
                            <h3 class="text-xl font-semibold text-center mb-4">Upload Audio File</h3>
                            <form id="uploadForm" enctype="multipart/form-data">
                                <div class="upload-area" id="uploadArea">
                                    <input type="file" id="audioFile" name="file" accept="audio/*" class="file-input">
                                    <label for="audioFile" class="file-label">Choose File</label>
                                    <p class="mt-4 text-gray-600">or drag and drop your audio file here</p>
                                    <p class="text-sm mt-2 text-gray-500">Supported formats: WAV, MP3, OGG</p>
                                </div>
                                <div class="model-select-container">
                                    <label for="modelType">Select Model:</label>
                                    <select id="modelType" name="model_type">
                                        <option value="wgan">WGAN Model</option>
                                        <option value="bi_gru">Bi-GRU-RNN Model</option>
                                    </select>
                                </div>
                                <button type="submit" class="upload-button" id="analyzeButton">Analyze Audio</button>
                            </form>
                        </div>
                    </div>
                    
                    <!-- Record Live Audio Section -->
                    <div class="bg-white rounded-lg shadow-lg p-6">
                        <div class="recording-container">
                            <h3 class="text-xl font-semibold text-center mb-4">Record Live Audio</h3>
                            <p class="text-center text-gray-600 mb-4">Record a 3-second audio clip and analyze it instantly</p>
                            
                            <div class="flex flex-col items-center">
                                <!-- Recording Status -->
                                <div id="recordingStatus" class="text-lg font-medium mb-4 text-center">Click to start recording</div>
                                
                                <!-- Recording Timer -->
                                <div id="recordingTimer" class="text-3xl font-bold mb-6 hidden">3</div>
                                
                                <!-- Record Button -->
                                <button id="recordButton" class="record-button mb-4">
                                    <svg class="w-12 h-12" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg">
                                        <circle cx="10" cy="10" r="8" />
                                    </svg>
                                </button>
                                
                                <!-- Audio Playback (for recorded audio) -->
                                <div id="recordedAudioContainer" class="w-full max-w-md mb-4 hidden">
                                    <audio id="recordedAudio" controls class="w-full"></audio>
                                </div>
                                
                                <!-- Model Selection for Recording -->
                                <div class="model-select-container">
                                    <label for="recordModelType">Select Model:</label>
                                    <select id="recordModelType" name="model_type">
                                        <option value="wgan">WGAN Model</option>
                                        <option value="bi_gru">Bi-GRU-RNN Model</option>
                                    </select>
                                </div>
                                
                                <!-- Analyze Recorded Audio Button -->
                                <button id="analyzeRecordedButton" class="upload-button mt-4 hidden">Analyze Recorded Audio</button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div id="loadingSpinner" class="loading-spinner">
                <div class="text-center">
                    <svg class="animate-spin mx-auto h-12 w-12 text-blue-500" fill="none" viewBox="0 0 24 24">
                        <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                        <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                    </svg>
                    <p class="mt-4 text-lg font-medium text-gray-700">Processing audio file...</p>
                </div>
            </div>

            <div id="resultCard" class="result-card bg-white rounded-lg shadow-lg p-6 mb-8 hidden">
                <h2 class="text-2xl font-semibold text-center mb-4">Analysis Result</h2>
                <div class="text-center">
                    <p class="text-xl font-medium mb-2" id="resultText"></p>
                    <p class="text-gray-600" id="confidenceText"></p>
                    <p class="text-gray-600" id="modelUsedText"></p>
                </div>
                
                <!-- Audio Player -->
                <div class="mt-6 border-t pt-6">
                    <h3 class="text-lg font-semibold text-center mb-4">Listen to the Audio</h3>
                    <div class="flex justify-center">
                        <audio id="audioPlayer" controls class="w-full max-w-md">
                            Your browser does not support the audio element.
                        </audio>
                    </div>
                </div>
            </div>
            
            <div id="visualizationSection" class="visualization-section hidden">
                <h2 class="text-2xl font-semibold text-center mb-6">Audio Visualizations</h2>
                
                <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                    <!-- Mel Spectrogram -->
                    <div class="visualization-card bg-white rounded-lg shadow-lg p-4">
                        <h3 class="text-lg font-semibold mb-2">Mel Spectrogram</h3>
                        <p class="text-sm text-gray-600 mb-2">Shows frequency content over time using the mel scale (perceptual scale of pitches).</p>
                        <div id="melSpectrogramContainer" class="w-full">
                            <img id="melSpectrogram" class="w-full rounded" alt="Mel Spectrogram" />
                        </div>
                    </div>
                    
                    <!-- Waveform -->
                    <div class="visualization-card bg-white rounded-lg shadow-lg p-4">
                        <h3 class="text-lg font-semibold mb-2">Waveform</h3>
                        <p class="text-sm text-gray-600 mb-2">Visual representation of the sound's amplitude over time.</p>
                        <div id="waveformContainer" class="w-full">
                            <img id="waveform" class="w-full rounded" alt="Waveform" />
                        </div>
                    </div>
                    
                    <!-- Chromagram -->
                    <div class="visualization-card bg-white rounded-lg shadow-lg p-4">
                        <h3 class="text-lg font-semibold mb-2">Chromagram</h3>
                        <p class="text-sm text-gray-600 mb-2">Shows the distribution of energy across the 12 pitch classes.</p>
                        <div id="chromagramContainer" class="w-full">
                            <img id="chromagram" class="w-full rounded" alt="Chromagram" />
                        </div>
                    </div>
                    
                    <!-- Spectral Contrast -->
                    <div class="visualization-card bg-white rounded-lg shadow-lg p-4">
                        <h3 class="text-lg font-semibold mb-2">Spectral Contrast</h3>
                        <p class="text-sm text-gray-600 mb-2">Shows the difference between peaks and valleys in the spectrum.</p>
                        <div id="spectralContrastContainer" class="w-full">
                            <img id="spectralContrast" class="w-full rounded" alt="Spectral Contrast" />
                        </div>
                    </div>
                    
                    <!-- MFCC -->
                    <div class="visualization-card bg-white rounded-lg shadow-lg p-4">
                        <h3 class="text-lg font-semibold mb-2">MFCC</h3>
                        <p class="text-sm text-gray-600 mb-2">Mel-frequency cepstral coefficients - compact representation of the spectrum.</p>
                        <div id="mfccContainer" class="w-full">
                            <img id="mfcc" class="w-full rounded" alt="MFCC" />
                        </div>
                    </div>
                </div>
            </div>

            <div id="errorCard" class="bg-red-100 border border-red-400 text-red-700 px-4 py-3 rounded relative hidden" role="alert">
                <span class="block sm:inline" id="errorText"></span>
            </div>
        </div>
    </div>

    <script>
        const uploadArea = document.getElementById('uploadArea');
        const fileInput = document.getElementById('audioFile');
        const resultCard = document.getElementById('resultCard');
        const errorCard = document.getElementById('errorCard');
        const resultText = document.getElementById('resultText');
        const confidenceText = document.getElementById('confidenceText');
        const errorText = document.getElementById('errorText');
        const visualizationSection = document.getElementById('visualizationSection');
        const loadingSpinner = document.getElementById('loadingSpinner');
        const analyzeButton = document.getElementById('analyzeButton');
        const melSpectrogram = document.getElementById('melSpectrogram');
        const waveform = document.getElementById('waveform');
        const chromagram = document.getElementById('chromagram');
        const spectralContrast = document.getElementById('spectralContrast');
        const mfcc = document.getElementById('mfcc');

        // Handle drag and drop
        uploadArea.addEventListener('dragover', (e) => {
            e.preventDefault();
            uploadArea.classList.add('border-blue-500');
        });

        uploadArea.addEventListener('dragleave', () => {
            uploadArea.classList.remove('border-blue-500');
        });

        uploadArea.addEventListener('drop', (e) => {
            e.preventDefault();
            uploadArea.classList.remove('border-blue-500');
            const file = e.dataTransfer.files[0];
            if (file) {
                fileInput.files = e.dataTransfer.files;
                updateFileName(file.name);
            }
        });

        // Handle click to upload
        uploadArea.addEventListener('click', () => {
            fileInput.click();
        });

        fileInput.addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (file) {
                updateFileName(file.name);
            }
        });

        function updateFileName(fileName) {
            const label = uploadArea.querySelector('.file-label');
            label.textContent = fileName;
            analyzeButton.disabled = false;
        }

        document.getElementById('uploadForm').addEventListener('submit', function(e) {
            e.preventDefault();
            const formData = new FormData();
            const fileInput = document.getElementById('audioFile');
            const modelType = document.getElementById('modelType').value;
            
            if (fileInput.files.length === 0) {
                showError('Please select an audio file');
                return;
            }
            
            formData.append('file', fileInput.files[0]);
            formData.append('model_type', modelType);
            
            // Show loading state
            resultCard.classList.add('hidden');
            errorCard.classList.add('hidden');
            visualizationSection.classList.add('hidden');
            loadingSpinner.style.display = 'block';
            analyzeButton.disabled = true;
            
            fetch('/predict', {
                method: 'POST',
                body: formData
            })
            .then(response => response.json())
            .then(data => {
                if (data.error) {
                    throw new Error(data.error);
                }
                showResult(data);
                showVisualizations(data.visualizations);
            })
            .catch(error => {
                console.error('Error:', error);
                showError(error.message);
            })
            .finally(() => {
                loadingSpinner.style.display = 'none';
                analyzeButton.disabled = false;
            });
        });

        function showResult(data) {
            resultCard.classList.remove('hidden');
            errorCard.classList.add('hidden');
            
            // Update result text
            resultText.textContent = `This audio is ${data.result}`;
            confidenceText.textContent = `Confidence: ${parseFloat(data.confidence).toFixed(2)}%`;
            modelUsedText.textContent = `Model Used: ${data.model_used.toUpperCase()}`;
            
            // Add color based on result
            resultText.classList.remove('text-green-600', 'text-red-600');
            if (data.result === 'Real') {
                resultText.classList.add('text-green-600');
            } else {
                resultText.classList.add('text-red-600');
            }
            
            // Update audio player
            if (data.audio_file) {
                const audioPlayer = document.getElementById('audioPlayer');
                audioPlayer.src = data.audio_file;
                audioPlayer.parentElement.parentElement.classList.remove('hidden');
            }
        }
        
        function showVisualizations(visualizations) {
            if (!visualizations) {
                visualizationSection.classList.add('hidden');
                return;
            }
            
            visualizationSection.classList.remove('hidden');
            
            // Set image sources
            if (visualizations.mel_spectrogram) {
                melSpectrogram.src = `/${visualizations.mel_spectrogram}`;
                melSpectrogram.parentElement.classList.remove('hidden');
            }
            
            if (visualizations.waveform) {
                waveform.src = `/${visualizations.waveform}`;
                waveform.parentElement.classList.remove('hidden');
            }
            
            if (visualizations.chromagram) {
                chromagram.src = `/${visualizations.chromagram}`;
                chromagram.parentElement.classList.remove('hidden');
            }
            
            if (visualizations.spectral_contrast) {
                spectralContrast.src = `/${visualizations.spectral_contrast}`;
                spectralContrast.parentElement.classList.remove('hidden');
            }
            
            if (visualizations.mfcc) {
                mfcc.src = `/${visualizations.mfcc}`;
                mfcc.parentElement.classList.remove('hidden');
            }
        }

        function showError(message) {
            errorCard.classList.remove('hidden');
            resultCard.classList.add('hidden');
            visualizationSection.classList.add('hidden');
            errorText.textContent = message;
        }
    </script>
    
    <!-- Audio Recording Scripts -->
    <script>
        // DOM Elements
        const recordButton = document.getElementById('recordButton');
        const recordingStatus = document.getElementById('recordingStatus');
        const recordingTimer = document.getElementById('recordingTimer');
        const recordedAudioContainer = document.getElementById('recordedAudioContainer');
        const recordedAudio = document.getElementById('recordedAudio');
        const analyzeRecordedButton = document.getElementById('analyzeRecordedButton');
        
        // Global variables
        let mediaRecorder;
        let audioChunks = [];
        let recordingTimeLeft = 3;
        let timerInterval;
        let audioBlob;
        
        // Check if browser supports getUserMedia
        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
            // Add event listener to record button
            recordButton.addEventListener('click', toggleRecording);
        } else {
            recordingStatus.textContent = 'Your browser does not support audio recording';
            recordButton.disabled = true;
        }
        
        // Add event listener to analyze button
        analyzeRecordedButton.addEventListener('click', analyzeRecordedAudio);
        
        // Function to toggle recording
        function toggleRecording() {
            if (!mediaRecorder) {
                startRecording();
            }
        }
        
        // Function to start recording
        function startRecording() {
            // Request microphone access
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    // Update UI
                    recordButton.classList.add('recording');
                    recordingStatus.textContent = 'Recording...';
                    recordingTimer.classList.remove('hidden');
                    recordedAudioContainer.classList.add('hidden');
                    analyzeRecordedButton.classList.add('hidden');
                    
                    // Reset variables
                    audioChunks = [];
                    recordingTimeLeft = 3;
                    recordingTimer.textContent = recordingTimeLeft;
                    
                    // Create media recorder
                    mediaRecorder = new MediaRecorder(stream);
                    
                    // Event handler for when data is available
                    mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0) {
                            audioChunks.push(event.data);
                        }
                    };
                    
                    // Event handler for when recording stops
                    mediaRecorder.onstop = () => {
                        // Create audio blob
                        audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                        
                        // Create URL for audio playback
                        const audioUrl = URL.createObjectURL(audioBlob);
                        recordedAudio.src = audioUrl;
                        
                        // Update UI
                        recordedAudioContainer.classList.remove('hidden');
                        analyzeRecordedButton.classList.remove('hidden');
                        recordingStatus.textContent = 'Recording complete';
                        
                        // Stop all audio tracks
                        stream.getAudioTracks().forEach(track => track.stop());
                        mediaRecorder = null;
                    };
                    
                    // Start recording
                    mediaRecorder.start();
                    
                    // Start timer
                    timerInterval = setInterval(() => {
                        recordingTimeLeft--;
                        recordingTimer.textContent = recordingTimeLeft;
                        
                        if (recordingTimeLeft <= 0) {
                            stopRecording();
                        }
                    }, 1000);
                })
                .catch(error => {
                    console.error('Error accessing microphone:', error);
                    recordingStatus.textContent = 'Error accessing microphone. Please check permissions.';
                    recordButton.classList.remove('recording');
                });
        }
        
        // Function to stop recording
        function stopRecording() {
            // Clear timer
            clearInterval(timerInterval);
            recordingTimer.classList.add('hidden');
            
            // Stop recording if active
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                recordButton.classList.remove('recording');
            }
        }
        
        // Function to analyze recorded audio
        function analyzeRecordedAudio() {
            if (!audioBlob) {
                showError('No recorded audio to analyze');
                return;
            }
            
            // Create form data
            const formData = new FormData();
            formData.append('audio', audioBlob, 'recording.wav');
            formData.append('model_type', document.getElementById('recordModelType').value);
            
            // Show loading state
            resultCard.classList.add('hidden');
            errorCard.classList.add('hidden');
            visualizationSection.classList.add('hidden');
            loadingSpinner.style.display = 'block';
            analyzeRecordedButton.disabled = true;
            
            // Send recorded audio to server
            fetch('/upload-recorded-audio', {
                method: 'POST',
                body: formData
            })
            .then(response => response.json())
            .then(data => {
                if (data.error) {
                    throw new Error(data.error);
                }
                showResult(data);
                showVisualizations(data.visualizations);
            })
            .catch(error => {
                console.error('Error:', error);
                showError(error.message);
            })
            .finally(() => {
                loadingSpinner.style.display = 'none';
                analyzeRecordedButton.disabled = false;
            });
        }
    </script>
</body>
</html> 