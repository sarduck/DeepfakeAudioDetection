{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 20:52:45.027240: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-09 20:52:45.038833: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744212165.052486 1786408 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744212165.056531 1786408 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744212165.067280 1786408 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744212165.067296 1786408 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744212165.067297 1786408 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744212165.067298 1786408 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-09 20:52:45.070544: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Conv1D, MaxPooling1D, GRU, Dense,\n",
    "                                     Dropout, BatchNormalization, LayerNormalization,\n",
    "                                     Bidirectional, Add, Attention)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import (confusion_matrix, f1_score, roc_curve, auc,\n",
    "                             classification_report)\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import noisereduce as nr\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, sosfilt\n",
    "from scipy.fftpack import dct\n",
    "import seaborn as sns\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "import time # For timing evaluation\n",
    "\n",
    "# Optional: Suppress TensorFlow/CUDA warnings for cleaner output in notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Filter TF messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "# Configure TensorFlow to use GPU and manage memory growth\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        # Use only the first GPU\n",
    "        tf.config.set_visible_devices(physical_devices[0], 'GPU')\n",
    "        # Allow memory growth to prevent allocating all GPU memory at once\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        print(f\"Using GPU: {physical_devices[0]}\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU devices found, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_audio(file_path, sr=16000, duration=4, augment=True):\n",
    "    \"\"\"Loads audio, applies augmentation (optional), normalizes, and pads/truncates.\"\"\"\n",
    "    try:\n",
    "        target_len = sr * duration\n",
    "        audio, current_sr = librosa.load(file_path, sr=sr, duration=None) # Load full duration initially\n",
    "\n",
    "        # Data Augmentation (only if augment=True, typically for training)\n",
    "        if augment and np.random.random() < 0.5:  # 50% chance\n",
    "            choice = np.random.choice(['noise', 'pitch', 'speed'])\n",
    "            if choice == 'noise':\n",
    "                noise_amp = 0.005 * np.random.uniform(0.5, 1.5) * np.max(np.abs(audio))\n",
    "                audio = audio + noise_amp * np.random.normal(size=audio.shape[0])\n",
    "            elif choice == 'pitch':\n",
    "                pitch_factor = np.random.uniform(-2.5, 2.5)\n",
    "                audio = librosa.effects.pitch_shift(y=audio, sr=sr, n_steps=pitch_factor)\n",
    "            elif choice == 'speed':\n",
    "                speed_factor = np.random.uniform(0.85, 1.15)\n",
    "                audio = librosa.effects.time_stretch(y=audio, rate=speed_factor)\n",
    "\n",
    "        # Trim silence from beginning and end\n",
    "        audio, _ = librosa.effects.trim(audio, top_db=25)\n",
    "\n",
    "        # Pad or truncate to target duration\n",
    "        if len(audio) > target_len:\n",
    "            # Take a random crop if longer\n",
    "            start = np.random.randint(0, len(audio) - target_len + 1)\n",
    "            audio = audio[start:start + target_len]\n",
    "        elif len(audio) < target_len:\n",
    "            # Pad with zeros if shorter\n",
    "            audio = np.pad(audio, (0, target_len - len(audio)), mode='constant')\n",
    "        else:\n",
    "            audio = audio[:target_len] # Ensure exact length\n",
    "\n",
    "\n",
    "        # Normalize audio to [-1, 1]\n",
    "        max_amp = np.max(np.abs(audio))\n",
    "        if max_amp > 1e-5: # Avoid division by zero\n",
    "             audio = audio / max_amp\n",
    "\n",
    "        return audio\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading/processing {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature Parameters ---\n",
    "SR = 16000\n",
    "N_FFT = 512 # Reduced for lighter computation\n",
    "HOP_LENGTH = 160 # Reduced hop length for more frames\n",
    "N_MELS = 64   # Reduced number of Mel bins\n",
    "N_MFCC = 13   # Standard MFCC count\n",
    "N_CQT_BINS = N_MELS # Use same number of bins as Mels for simplicity/consistency\n",
    "BINS_PER_OCTAVE = 12\n",
    "N_CQCC = 13 # Similar count to MFCC\n",
    "\n",
    "# --- Calculate Total Features ---\n",
    "TOTAL_FEATURES = N_MELS + N_MFCC + N_CQT_BINS + N_CQCC # 64 + 13 + 64 + 13 = 154\n",
    "\n",
    "def extract_features(audio, sr=SR, n_mels=N_MELS, n_mfcc=N_MFCC, n_cqt_bins=N_CQT_BINS,\n",
    "                     bins_per_octave=BINS_PER_OCTAVE, n_cqcc=N_CQCC,\n",
    "                     n_fft=N_FFT, hop_length=HOP_LENGTH):\n",
    "    \"\"\"\n",
    "    Extracts Mel Spectrogram, MFCC, CQT (magnitude), and CQCC features,\n",
    "    normalizes each individually, aligns time steps, and concatenates them.\n",
    "    Returns shape (time_steps, features).\n",
    "    \"\"\"\n",
    "    if audio is None:\n",
    "        return None\n",
    "\n",
    "    features_list = []\n",
    "    min_time_steps = float('inf') # Keep track of minimum time steps\n",
    "\n",
    "    # 1. Mel Spectrogram\n",
    "    try:\n",
    "        mel_spec = librosa.feature.melspectrogram(\n",
    "            y=audio, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length\n",
    "        )\n",
    "        log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        log_mel_spec = (log_mel_spec - np.mean(log_mel_spec)) / (np.std(log_mel_spec) + 1e-8)\n",
    "        features_list.append(log_mel_spec)\n",
    "        min_time_steps = min(min_time_steps, log_mel_spec.shape[1])\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting Mel Spectrogram: {e}\")\n",
    "        return None # Fail if fundamental features missing\n",
    "\n",
    "    # 2. MFCC\n",
    "    try:\n",
    "        mfccs = librosa.feature.mfcc(\n",
    "            y=audio, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels\n",
    "        )\n",
    "        mfccs = (mfccs - np.mean(mfccs)) / (np.std(mfccs) + 1e-8)\n",
    "        features_list.append(mfccs)\n",
    "        min_time_steps = min(min_time_steps, mfccs.shape[1])\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting MFCC: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 3. CQT (Magnitude)\n",
    "    try:\n",
    "        # Adjust CQT parameters if needed to match time dimension roughly\n",
    "        cqt = librosa.cqt(\n",
    "            y=audio, sr=sr, hop_length=hop_length,\n",
    "            n_bins=n_cqt_bins, bins_per_octave=bins_per_octave,\n",
    "            fmin=librosa.note_to_hz('C2'), # Adjusted fmin slightly\n",
    "            tuning=0.0 # No tuning offset\n",
    "        )\n",
    "        log_cqt_mag = librosa.amplitude_to_db(np.abs(cqt), ref=np.max)\n",
    "        log_cqt_mag = (log_cqt_mag - np.mean(log_cqt_mag)) / (np.std(log_cqt_mag) + 1e-8)\n",
    "        features_list.append(log_cqt_mag)\n",
    "        min_time_steps = min(min_time_steps, log_cqt_mag.shape[1])\n",
    "\n",
    "        # 4. CQCC (derived from CQT)\n",
    "        try:\n",
    "            cqccs = dct(log_cqt_mag, axis=0, type=2, norm='ortho')[:n_cqcc, :]\n",
    "            cqccs = (cqccs - np.mean(cqccs)) / (np.std(cqccs) + 1e-8)\n",
    "            features_list.append(cqccs)\n",
    "            min_time_steps = min(min_time_steps, cqccs.shape[1])\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting CQCC: {e}\")\n",
    "            return None # Fail if CQCC fails\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting CQT (required for CQCC): {e}\")\n",
    "        return None # Fail if CQT fails\n",
    "\n",
    "\n",
    "    # Align time steps by truncating to the minimum length found\n",
    "    aligned_features = [f[:, :min_time_steps] for f in features_list]\n",
    "\n",
    "    # Concatenate features along the feature axis (axis=0)\n",
    "    combined_features = np.concatenate(aligned_features, axis=0)\n",
    "\n",
    "    # Transpose to get (time_steps, features)\n",
    "    return combined_features.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_class_distribution(data_path):\n",
    "    \"\"\"Analyzes and prints the class distribution in a given directory.\"\"\"\n",
    "    try:\n",
    "        real_path = os.path.join(data_path, 'real')\n",
    "        fake_path = os.path.join(data_path, 'fake')\n",
    "\n",
    "        real_count = len([f for f in os.listdir(real_path) if f.lower().endswith(('.wav', '.flac'))]) if os.path.exists(real_path) else 0\n",
    "        fake_count = len([f for f in os.listdir(fake_path) if f.lower().endswith(('.wav', '.flac'))]) if os.path.exists(fake_path) else 0\n",
    "        total = real_count + fake_count\n",
    "\n",
    "        print(f\"\\nClass Distribution for {data_path}:\")\n",
    "        if total > 0:\n",
    "            print(f\"Real: {real_count} ({real_count/total*100:.2f}%)\")\n",
    "            print(f\"Fake: {fake_count} ({fake_count/total*100:.2f}%)\")\n",
    "        else:\n",
    "            print(\"Real: 0 (0.00%)\")\n",
    "            print(\"Fake: 0 (0.00%)\")\n",
    "            print(\"Warning: No audio files found in specified directory.\")\n",
    "        return {'real': real_count, 'fake': fake_count}\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Directory not found - {data_path}\")\n",
    "        return {'real': 0, 'fake': 0}\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing {data_path}: {e}\")\n",
    "        return {'real': 0, 'fake': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data_path, batch_size=64, shuffle=True, augment=True):\n",
    "    \"\"\"Generates batches of data (X, y, sample_weights) with dynamic padding.\"\"\"\n",
    "    try:\n",
    "        real_path = os.path.join(data_path, 'real')\n",
    "        fake_path = os.path.join(data_path, 'fake')\n",
    "        real_files = [os.path.join(real_path, f) for f in os.listdir(real_path) if f.lower().endswith(('.wav', '.flac'))] if os.path.exists(real_path) else []\n",
    "        fake_files = [os.path.join(fake_path, f) for f in os.listdir(fake_path) if f.lower().endswith(('.wav', '.flac'))] if os.path.exists(fake_path) else []\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Cannot find 'real' or 'fake' subdirectories in {data_path}\")\n",
    "        # Yield an empty batch to avoid infinite loops if the generator is expected to produce something\n",
    "        yield np.array([]), np.array([]), np.array([])\n",
    "        return # Stop the generator\n",
    "\n",
    "    if not real_files and not fake_files:\n",
    "        print(f\"Warning: No audio files found in {data_path}\")\n",
    "        yield np.array([]), np.array([]), np.array([])\n",
    "        return\n",
    "\n",
    "    # Assign labels (Real=1, Fake=0, as per common convention in fraud detection)\n",
    "    all_files = real_files + fake_files\n",
    "    labels = [1] * len(real_files) + [0] * len(fake_files)\n",
    "\n",
    "    # Calculate class weights for handling imbalance\n",
    "    total_samples = len(all_files)\n",
    "    weight_for_0 = (1 / len(fake_files)) * (total_samples / 2.0) if len(fake_files) > 0 else 0\n",
    "    weight_for_1 = (1 / len(real_files)) * (total_samples / 2.0) if len(real_files) > 0 else 0\n",
    "    class_weights = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "    file_label_list = list(zip(all_files, labels))\n",
    "\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(file_label_list)\n",
    "\n",
    "        for i in range(0, len(file_label_list), batch_size):\n",
    "            batch_list = file_label_list[i:i+batch_size]\n",
    "            batch_files, batch_labels = zip(*batch_list) if batch_list else ([], [])\n",
    "\n",
    "            batch_x_features = []\n",
    "            batch_y_labels = []\n",
    "            batch_sample_weights = []\n",
    "            max_len_in_batch = 0\n",
    "\n",
    "            for file_path, label in zip(batch_files, batch_labels):\n",
    "                # Load audio, use augmentation status passed to generator\n",
    "                audio = load_and_preprocess_audio(file_path, sr=SR, augment=augment)\n",
    "                if audio is None: continue # Skip if loading failed\n",
    "\n",
    "                # Extract combined features\n",
    "                features = extract_features(audio, sr=SR)\n",
    "                if features is None: continue # Skip if feature extraction failed\n",
    "\n",
    "                if features.shape[0] > 0: # Check if features are not empty\n",
    "                    batch_x_features.append(features)\n",
    "                    batch_y_labels.append(label)\n",
    "                    batch_sample_weights.append(class_weights[label])\n",
    "                    max_len_in_batch = max(max_len_in_batch, features.shape[0]) # Find max time steps in THIS batch\n",
    "\n",
    "            if not batch_x_features: # If batch ended up empty, skip\n",
    "                continue\n",
    "\n",
    "            # Pad sequences dynamically within the batch\n",
    "            padded_batch_x = np.zeros((len(batch_x_features), max_len_in_batch, TOTAL_FEATURES), dtype=np.float32)\n",
    "            for idx, x in enumerate(batch_x_features):\n",
    "                seq_len = x.shape[0]\n",
    "                padded_batch_x[idx, :seq_len, :] = x\n",
    "\n",
    "            yield padded_batch_x, np.array(batch_y_labels), np.array(batch_sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFM(Layer):\n",
    "    \"\"\"Max-Feature-Map activation function.\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MFM, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Assumes channels_last format (batch, time_steps, features)\n",
    "        shape = tf.shape(inputs)\n",
    "        features_dim = inputs.shape[-1]\n",
    "        if features_dim is None or features_dim % 2 != 0:\n",
    "             raise ValueError(\"MFM activation requires an even number of filters/features.\")\n",
    "        # Split features in half along the last dimension\n",
    "        split1 = inputs[..., :features_dim // 2]\n",
    "        split2 = inputs[..., features_dim // 2:]\n",
    "        return tf.maximum(split1, split2)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[-1] //= 2\n",
    "        return tuple(output_shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(MFM, self).get_config()\n",
    "        return base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lightweight_cnn_bigru_model(input_shape, l2_reg=0.01):\n",
    "    \"\"\"Creates a lightweight CNN-BiGRU model with MFM and residual connections.\"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = BatchNormalization(name='input_bn')(inputs)\n",
    "\n",
    "    # --- Lightweight Convolutional Blocks ---\n",
    "    # Block 1\n",
    "    # Conv1D needs double filters because MFM halves them\n",
    "    x = Conv1D(32, 5, padding='same', kernel_regularizer=l2(l2_reg), name='conv1')(x)\n",
    "    x = MFM(name='mfm1')(x) # Apply MFM (replaces standard activation here)\n",
    "    x = MaxPooling1D(pool_size=2, name='pool1')(x)\n",
    "    x = Dropout(0.3, name='drop1')(x) # Slightly lower dropout\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv1D(64, 3, padding='same', kernel_regularizer=l2(l2_reg), name='conv2')(x)\n",
    "    x = MFM(name='mfm2')(x)\n",
    "    x = MaxPooling1D(pool_size=2, name='pool2')(x)\n",
    "    x = Dropout(0.3, name='drop2')(x)\n",
    "\n",
    "    # --- Residual Bidirectional GRU Blocks ---\n",
    "    # Reduced units for lightweight design\n",
    "    for i, units in enumerate([32, 16]): # Effective units (output dimension of BiGRU)\n",
    "        shortcut = x # Store the input to the block as the shortcut path\n",
    "\n",
    "        # Main path: BiGRU\n",
    "        gru = Bidirectional(GRU(units // 2, return_sequences=True,\n",
    "                                kernel_regularizer=l2(l2_reg)), name=f'bi_gru_{i+1}')\n",
    "        gru_output = gru(x) # Output shape: (None, time_steps, units)\n",
    "\n",
    "        # Shortcut path: Project the original input `shortcut` if needed\n",
    "        shortcut_channels = K.int_shape(shortcut)[-1]\n",
    "        if shortcut_channels != units:\n",
    "            # Project shortcut to match the output dimension of the GRU layer\n",
    "            shortcut_proj = Dense(units, kernel_regularizer=l2(l2_reg), name=f'shortcut_proj_{i+1}')(shortcut)\n",
    "        else:\n",
    "            # No projection needed if dimensions already match\n",
    "            shortcut_proj = shortcut\n",
    "\n",
    "        # Add the main path output (gru_output) and the (possibly projected) shortcut path\n",
    "        x = Add(name=f'add_res_{i+1}')([shortcut_proj, gru_output])\n",
    "\n",
    "        # Apply post-addition layers\n",
    "        x = LayerNormalization(name=f'ln_gru_{i+1}')(x)\n",
    "        x = Dropout(0.4, name=f'drop_gru_{i+1}')(x) # Keep reasonable dropout\n",
    "\n",
    "    # --- Attention Mechanism ---\n",
    "    attention_out = Attention(name='attention')([x, x])\n",
    "    x = Add(name='add_attn')([x, attention_out])\n",
    "\n",
    "    # --- Final Bi-GRU Aggregation ---\n",
    "    # Further reduced units\n",
    "    x = Bidirectional(GRU(8, kernel_regularizer=l2(l2_reg)), name='final_bi_gru')(x)\n",
    "    x = LayerNormalization(name='ln_final_gru')(x)\n",
    "    x = Dropout(0.4, name='drop_final_gru')(x)\n",
    "\n",
    "    # --- Classification Head ---\n",
    "    # Reduced dense units\n",
    "    x = Dense(16, activation='relu', kernel_regularizer=l2(l2_reg), name='dense1')(x)\n",
    "    x = Dropout(0.5, name='drop_dense1')(x) # Keep higher dropout before final layer\n",
    "\n",
    "    outputs = Dense(1, activation='sigmoid', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Data Distribution:\n",
      "\n",
      "Class Distribution for datasetNEW/train:\n",
      "Real: 2580 (10.17%)\n",
      "Fake: 22800 (89.83%)\n",
      "\n",
      "Class Distribution for datasetNEW/dev:\n",
      "Real: 2548 (10.26%)\n",
      "Fake: 22296 (89.74%)\n",
      "\n",
      "Class Distribution for datasetNEW/eval:\n",
      "Real: 7355 (10.32%)\n",
      "Fake: 63882 (89.68%)\n"
     ]
    }
   ],
   "source": [
    "# --- Paths to your dataset ---\n",
    "# !!! IMPORTANT: Update these paths to match your dataset structure !!!\n",
    "base_data_path = 'datasetNEW' # Or wherever your train/dev/eval folders are\n",
    "train_data_path = os.path.join(base_data_path, 'train')\n",
    "dev_data_path = os.path.join(base_data_path, 'dev')\n",
    "eval_data_path = os.path.join(base_data_path, 'eval')\n",
    "\n",
    "# --- Analyze class distribution ---\n",
    "print(\"Analyzing Data Distribution:\")\n",
    "dist_train = analyze_class_distribution(train_data_path)\n",
    "dist_dev = analyze_class_distribution(dev_data_path)\n",
    "dist_eval = analyze_class_distribution(eval_data_path)\n",
    "\n",
    "# Check if datasets were found\n",
    "if dist_train['real'] + dist_train['fake'] == 0:\n",
    "    print(\"\\nError: No training data found. Please check 'train_data_path'.\")\n",
    "if dist_dev['real'] + dist_dev['fake'] == 0:\n",
    "    print(\"\\nError: No validation data found. Please check 'dev_data_path'.\")\n",
    "if dist_eval['real'] + dist_eval['fake'] == 0:\n",
    "    print(\"\\nError: No evaluation data found. Please check 'eval_data_path'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generator Setup ---\n",
      "Batch Size: 64\n",
      "Total Train Samples: 25380, Steps Per Epoch: 396\n",
      "Total Validation Samples: 24844, Validation Steps: 388\n",
      "Total Evaluation Samples: 71237, Evaluation Steps: 1113\n",
      "Sample Batch Shapes - X: (64, 401, 154), y: (64,), weights: (64,)\n"
     ]
    }
   ],
   "source": [
    "#Cell 10: Generator Instantiation and Step Calculation\n",
    "\n",
    "def count_files(path):\n",
    "    \"\"\"Counts audio files in 'real' and 'fake' subdirectories.\"\"\"\n",
    "    count = 0\n",
    "    try:\n",
    "        real_path = os.path.join(path, 'real')\n",
    "        fake_path = os.path.join(path, 'fake')\n",
    "        if os.path.exists(real_path):\n",
    "            count += len([f for f in os.listdir(real_path) if f.lower().endswith(('.wav', '.flac'))])\n",
    "        if os.path.exists(fake_path):\n",
    "            count += len([f for f in os.listdir(fake_path) if f.lower().endswith(('.wav', '.flac'))])\n",
    "    except FileNotFoundError:\n",
    "        # Error already printed by analyze_class_distribution\n",
    "        pass\n",
    "    return count\n",
    "\n",
    "# --- Create generators ---\n",
    "BATCH_SIZE = 64 # Can adjust based on GPU memory (64 is often reasonable)\n",
    "train_gen = data_generator(train_data_path, batch_size=BATCH_SIZE, shuffle=True, augment=True)\n",
    "dev_gen = data_generator(dev_data_path, batch_size=BATCH_SIZE, shuffle=False, augment=False) # No augmentation for validation\n",
    "eval_gen_for_eval = data_generator(eval_data_path, batch_size=BATCH_SIZE, shuffle=False, augment=False) # For final evaluate()\n",
    "eval_gen_for_predict = data_generator(eval_data_path, batch_size=BATCH_SIZE, shuffle=False, augment=False) # Separate instance for predict()\n",
    "\n",
    "# --- Calculate steps ---\n",
    "train_samples_count = count_files(train_data_path)\n",
    "dev_samples_count = count_files(dev_data_path)\n",
    "eval_samples_count = count_files(eval_data_path)\n",
    "\n",
    "if BATCH_SIZE == 0:\n",
    "    raise ValueError(\"Batch size cannot be zero.\")\n",
    "\n",
    "steps_per_epoch = train_samples_count // BATCH_SIZE if train_samples_count > 0 else 1\n",
    "validation_steps = dev_samples_count // BATCH_SIZE if dev_samples_count > 0 else 1\n",
    "eval_steps = eval_samples_count // BATCH_SIZE if eval_samples_count > 0 else 1 # For evaluate/predict loops\n",
    "\n",
    "print(f\"\\n--- Generator Setup ---\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Total Train Samples: {train_samples_count}, Steps Per Epoch: {steps_per_epoch}\")\n",
    "print(f\"Total Validation Samples: {dev_samples_count}, Validation Steps: {validation_steps}\")\n",
    "print(f\"Total Evaluation Samples: {eval_samples_count}, Evaluation Steps: {eval_steps}\")\n",
    "\n",
    "# Simple check generator output shape once\n",
    "if train_samples_count > 0:\n",
    "    try:\n",
    "        sample_x, sample_y, sample_w = next(train_gen)\n",
    "        print(f\"Sample Batch Shapes - X: {sample_x.shape}, y: {sample_y.shape}, weights: {sample_w.shape}\")\n",
    "        # Reset generator after check if needed, or create a separate one for check\n",
    "        train_gen = data_generator(train_data_path, batch_size=BATCH_SIZE, shuffle=True, augment=True) # Recreate\n",
    "    except StopIteration:\n",
    "        print(\"Could not get a sample batch from the training generator.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting sample batch: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,         # Reduce LR by a factor of 5\n",
    "    patience=4,         # Reduce LR if no improvement for 4 epochs\n",
    "    min_lr=1e-7,        # Minimum learning rate\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', # Monitor validation loss\n",
    "    patience=10,        # Stop training if no improvement for 10 epochs\n",
    "    restore_best_weights=True, # Restore weights from the epoch with the best val_loss\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Optional: Save the best model checkpoint\n",
    "checkpoint_filepath = 'best_lightweight_model.keras'\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True, # Only save when val_loss improves\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks_list = [reduce_lr, early_stopping, model_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744212172.050266 1786408 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1522 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">154</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_bn            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">154</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">616</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,672</span> │ input_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mfm1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MFM</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pool1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mfm1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drop1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pool1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │ drop1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mfm2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MFM</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pool2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mfm2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drop2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pool2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bi_gru_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,800</span> │ drop2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_res_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ drop2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ bi_gru_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ln_gru_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ add_res_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drop_gru_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ln_gru_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ shortcut_proj_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ drop_gru_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bi_gru_2            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,016</span> │ drop_gru_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_res_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ shortcut_proj_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ bi_gru_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ln_gru_2            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ add_res_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drop_gru_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ln_gru_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ drop_gru_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ drop_gru_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_attn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ drop_gru_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_bi_gru        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,248</span> │ add_attn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ln_final_gru        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ final_bi_gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drop_final_gru      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ln_final_gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │ drop_final_gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drop_dense1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ drop_dense1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m154\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_bn            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m154\u001b[0m) │        \u001b[38;5;34m616\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1 (\u001b[38;5;33mConv1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m24,672\u001b[0m │ input_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mfm1 (\u001b[38;5;33mMFM\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pool1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ mfm1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drop1 (\u001b[38;5;33mDropout\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ pool1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2 (\u001b[38;5;33mConv1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │      \u001b[38;5;34m3,136\u001b[0m │ drop1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mfm2 (\u001b[38;5;33mMFM\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pool2               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ mfm2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drop2 (\u001b[38;5;33mDropout\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ pool2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bi_gru_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │      \u001b[38;5;34m4,800\u001b[0m │ drop2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_res_1 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ drop2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ bi_gru_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ln_gru_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ add_res_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drop_gru_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ ln_gru_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ shortcut_proj_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │        \u001b[38;5;34m528\u001b[0m │ drop_gru_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bi_gru_2            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │      \u001b[38;5;34m2,016\u001b[0m │ drop_gru_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_res_2 (\u001b[38;5;33mAdd\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ shortcut_proj_2[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ bi_gru_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ln_gru_2            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m32\u001b[0m │ add_res_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drop_gru_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ ln_gru_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ drop_gru_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ drop_gru_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_attn (\u001b[38;5;33mAdd\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ drop_gru_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_bi_gru        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │      \u001b[38;5;34m1,248\u001b[0m │ add_attn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ln_final_gru        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m32\u001b[0m │ final_bi_gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drop_final_gru      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ ln_final_gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense1 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m272\u001b[0m │ drop_final_gru[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drop_dense1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m17\u001b[0m │ drop_dense1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37,433</span> (146.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m37,433\u001b[0m (146.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37,125</span> (145.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m37,125\u001b[0m (145.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">308</span> (1.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m308\u001b[0m (1.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and compile the model using the defined lightweight architecture\n",
    "input_shape_combined = (None, TOTAL_FEATURES) # (Time steps, Features)\n",
    "model = create_lightweight_cnn_bigru_model(input_shape_combined)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0005), # Slightly lower initial LR\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')] # Assign name to AUC metric\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Model Training ---\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744212183.322057 1786610 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m396/396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4406 - auc: 0.5096 - loss: 3.2081"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "EPOCHS = 60 # Adjust as needed, early stopping will likely trigger sooner\n",
    "\n",
    "print(\"\\n--- Starting Model Training ---\")\n",
    "history = None\n",
    "if train_samples_count > 0 and dev_samples_count > 0:\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=dev_gen,\n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=callbacks_list,\n",
    "        # Use class_weight from the generator if you didn't include sample_weight\n",
    "        # class_weight=class_weights, # If generator yielded only X, y\n",
    "        # Use sample_weight if generator yields X, y, sample_weight (as implemented)\n",
    "    )\n",
    "    print(\"\\n--- Training Finished ---\")\n",
    "else:\n",
    "    print(\"\\nSkipping training due to missing training or validation data.\")\n",
    "\n",
    "# Load best weights saved by ModelCheckpoint (redundant if restore_best_weights=True in EarlyStopping, but safe)\n",
    "if os.path.exists(checkpoint_filepath):\n",
    "     print(f\"Loading best weights from {checkpoint_filepath}\")\n",
    "     model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history if training was performed\n",
    "if history is not None:\n",
    "    print(\"\\n--- Plotting Training History ---\")\n",
    "    plt.figure(figsize=(15, 6))\n",
    "\n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.plot(history.history.get('auc', []), label='Training AUC') # Use .get for safety\n",
    "    plt.plot(history.history.get('val_auc', []), label='Validation AUC')\n",
    "    plt.title('Model Accuracy & AUC')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Loss Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping history plot as training was not performed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the evaluation set using model.evaluate()\n",
    "print(\"\\n--- Evaluating on Evaluation Dataset (using model.evaluate) ---\")\n",
    "eval_results = None\n",
    "if eval_samples_count > 0:\n",
    "    eval_results = model.evaluate(eval_gen_for_eval, steps=eval_steps, verbose=1)\n",
    "    print(f\"\\nEvaluation Results - Loss: {eval_results[0]:.4f}, Accuracy: {eval_results[1]:.4f}, AUC: {eval_results[2]:.4f}\")\n",
    "else:\n",
    "    print(\"Skipping evaluation due to missing evaluation data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Performing Advanced Evaluation (Predictions, CM, EER, t-DCF) ---\")\n",
    "\n",
    "y_pred_scores = []\n",
    "y_true_labels = []\n",
    "start_time = time.time()\n",
    "\n",
    "if eval_samples_count > 0:\n",
    "    print(f\"Generating predictions for {eval_samples_count} samples...\")\n",
    "    # Use the separate generator instance for prediction\n",
    "    for i in range(eval_steps + 1): # Add 1 to ensure all samples are covered if count isn't multiple of batch size\n",
    "        try:\n",
    "            batch_x, batch_y, _ = next(eval_gen_for_predict)\n",
    "            if batch_x.shape[0] == 0: continue # Skip empty batches\n",
    "            batch_pred = model.predict(batch_x, verbose=0)\n",
    "            y_pred_scores.extend(batch_pred.flatten())\n",
    "            y_true_labels.extend(batch_y)\n",
    "        except StopIteration:\n",
    "            break # Generator finished\n",
    "    print(f\"Prediction generation finished in {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "    # Ensure lists are numpy arrays and have the same length\n",
    "    y_pred_scores = np.array(y_pred_scores)\n",
    "    y_true_labels = np.array(y_true_labels)\n",
    "    min_len = min(len(y_pred_scores), len(y_true_labels), eval_samples_count) # Cap length\n",
    "    y_pred_scores = y_pred_scores[:min_len]\n",
    "    y_true_labels = y_true_labels[:min_len]\n",
    "\n",
    "    if len(y_true_labels) == 0:\n",
    "        print(\"No predictions generated or true labels available for advanced evaluation.\")\n",
    "    else:\n",
    "        # --- F1 Score and Classification Report ---\n",
    "        y_pred_binary = (y_pred_scores > 0.5).astype(int)\n",
    "        f1 = f1_score(y_true_labels, y_pred_binary)\n",
    "        print(f\"\\nF1 Score (Threshold 0.5): {f1:.4f}\")\n",
    "        print(\"\\nClassification Report (Threshold 0.5):\")\n",
    "        # Use zero_division=0 to handle cases where a class might not be predicted\n",
    "        print(classification_report(y_true_labels, y_pred_binary, target_names=['Fake (0)', 'Real (1)'], zero_division=0))\n",
    "\n",
    "        # --- Confusion Matrix ---\n",
    "        cm = confusion_matrix(y_true_labels, y_pred_binary)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label (0:Fake, 1:Real)')\n",
    "        plt.xlabel('Predicted Label (0:Fake, 1:Real)')\n",
    "        plt.show()\n",
    "\n",
    "        # --- EER Calculation ---\n",
    "        # Calculate False Positive Rate (FPR) and True Positive Rate (TPR)\n",
    "        # Note: roc_curve expects true labels (0 or 1) and prediction scores (probabilities)\n",
    "        fpr, tpr, thresholds = roc_curve(y_true_labels, y_pred_scores, pos_label=1) # Assuming Real=1 is positive\n",
    "        fnr = 1 - tpr # False Negative Rate\n",
    "\n",
    "        # Find the EER point where FPR is closest to FNR\n",
    "        eer_index = np.nanargmin(np.abs(fpr - fnr))\n",
    "        eer = (fpr[eer_index] + fnr[eer_index]) / 2.0 # Average FPR and FNR at intersection\n",
    "        eer_threshold = thresholds[eer_index]\n",
    "\n",
    "        print(f\"\\nEqual Error Rate (EER): {eer:.4f}\")\n",
    "        print(f\"EER Threshold: {eer_threshold:.4f}\")\n",
    "\n",
    "        # Plot ROC Curve with EER point\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc(fpr, tpr):.4f})')\n",
    "        plt.plot(fpr, fnr, label='FN Rate', linestyle='--') # Plot FNR vs FPR\n",
    "        plt.plot([0, 1], [1, 0], 'k--', label='Random guess') # Diagonal line\n",
    "        plt.scatter(fpr[eer_index], tpr[eer_index], color='red', zorder=5, label=f'EER ≈ {eer:.4f}')\n",
    "        plt.xlabel('False Positive Rate (FPR)')\n",
    "        plt.ylabel('True Positive Rate (TPR)')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve & EER')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        # --- t-DCF Calculation ---\n",
    "        # ASVspoof 2019 LA parameters (example)\n",
    "        p_target = 0.05  # Prior probability of target (bona fide/real) - Adjust if needed\n",
    "        c_miss = 1       # Cost of missing a spoof (FN for spoof detection -> FP for real detection)\n",
    "        c_fa_bona = 10   # Cost of false alarm on bona fide (FP for spoof detection -> FN for real detection)\n",
    "\n",
    "        def calculate_t_dcf(frate, farate, p_target, c_miss, c_fa):\n",
    "             \"\"\" Calculate t-DCF \"\"\"\n",
    "             dcf = c_miss * p_target * frate + c_fa * (1 - p_target) * farate\n",
    "             # Normalize DCF by the cost of always missing target and always accepting non-target\n",
    "             dcf_norm = dcf / min(c_miss * p_target, c_fa * (1 - p_target))\n",
    "             return dcf_norm # Return normalized t-DCF\n",
    "\n",
    "        # Calculate FAR and FRR at the EER threshold\n",
    "        # FAR (Spoof classified as Real) = FPR when Real=1 is positive class\n",
    "        # FRR (Real classified as Spoof) = FNR when Real=1 is positive class\n",
    "        far_at_eer = fpr[eer_index]\n",
    "        frr_at_eer = fnr[eer_index]\n",
    "\n",
    "        # Calculate t-DCF (using FRR as miss rate for target=Real, FAR as false alarm rate for non-target=Fake)\n",
    "        # Here, \"miss\" means missing a Real speaker (FRR), \"false alarm\" means misclassifying Fake as Real (FAR)\n",
    "        # Check ASVspoof definitions carefully for your specific task interpretation\n",
    "        # Assuming standard definition where target=bona fide (1):\n",
    "        # P_miss = FRR (Bona fide classified as Spoof)\n",
    "        # P_fa = FAR (Spoof classified as Bona fide)\n",
    "\n",
    "        t_dcf_eer = calculate_t_dcf(frr_at_eer, far_at_eer, p_target, c_miss=c_fa_bona, c_fa=c_miss) # Swapped costs based on definition above\n",
    "        print(f\"Normalized t-DCF (at EER threshold): {t_dcf_eer:.4f}\")\n",
    "\n",
    "        # Find minimum t-DCF across all thresholds\n",
    "        tdcf_values = [calculate_t_dcf(fnr[i], fpr[i], p_target, c_miss=c_fa_bona, c_fa=c_miss) for i in range(len(thresholds))]\n",
    "        min_tdcf_index = np.nanargmin(tdcf_values)\n",
    "        min_t_dcf = tdcf_values[min_tdcf_index]\n",
    "        min_tdcf_threshold = thresholds[min_tdcf_index]\n",
    "        print(f\"Minimum Normalized t-DCF: {min_t_dcf:.4f} at Threshold: {min_tdcf_threshold:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping advanced evaluation due to missing evaluation data or predictions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
